{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10886, 12)\n",
      "train is \n",
      "(10886, 10)\n",
      "labels train are \n",
      "(10886,)\n",
      "test is \n",
      "(6493, 10)\n",
      "Number of Negative values predicted are  24\n",
      "trainSplit is \n",
      "(8708, 10)  and testSplit is \n",
      "(2178, 10)\n",
      "ypred is \n",
      "[  45.96415231   45.28381731  185.60055065 ...,  137.16521297  130.73808505\n",
      "   94.32587411]\n",
      "test split is \n",
      "[ 19  19  68 ..., 168 129  88]\n",
      "the loss is  0.639331761758\n",
      "testd shape is  (6493, 10)\n",
      "Feature Ranking\n",
      "\n",
      "1. feature 8 Hour (0.490237)\n",
      "2. feature 2 workingday (0.117948)\n",
      "3. feature 6 humidity (0.097533)\n",
      "4. feature 4 temp (0.079519)\n",
      "5. feature 9 DayOfWeek (0.073352)\n",
      "6. feature 5 atemp (0.047066)\n",
      "7. feature 0 season (0.043905)\n",
      "8. feature 3 weather (0.023082)\n",
      "9. feature 7 windspeed (0.020010)\n",
      "10. feature 1 holiday (0.007349)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:102: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:104: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:105: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:106: DeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "#This Code trains an ensemble of Random Forests \n",
    "#and Gradient Boosted trees then averages the prediction of the two.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from copy import copy\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import csv\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "dateparse=lambda x:pd.datetime.strptime(x,'%Y-%m-%d %H:%M:%S')\n",
    "train=pd.read_csv('train.csv',parse_dates=['datetime'],date_parser=dateparse)\n",
    "test=pd.read_csv('test.csv',parse_dates=['datetime'],date_parser=dateparse)\n",
    "\n",
    "#This was required when the number of trees were less than 50. With more trees , almost same performace was achieved\n",
    "#test['windspeed']=np.log(test['windspeed']+1)\n",
    "#train['windspeed']=np.log(train['windspeed']+1)\n",
    "print train.shape\n",
    "\n",
    "def extractFeaturesTrain(data):\n",
    "    #print 'data is ',data\n",
    "    data['Hour']=data.datetime.dt.hour\n",
    "    data['DayOfWeek']=data.datetime.dt.dayofweek\n",
    "    #data['Month']=data.datetime.dt.month\n",
    "    labels=data['count']\n",
    "    train_years=data.datetime.dt.year\n",
    "    train_months=data.datetime.dt.month\n",
    "    data=data.drop(['datetime','count','casual','registered'], axis = 1)\n",
    "    \n",
    "    return np.array(data),np.array(labels),np.array(train_years),np.array(train_months),(data.columns.values)\n",
    "\n",
    "def extractFeaturesTest(data):\n",
    "    \n",
    "    data['Hour']=data.datetime.dt.hour\n",
    "    data['DayOfWeek']=data.datetime.dt.dayofweek\n",
    "    #data['Month']=data.datetime.dt.month\n",
    "    test_years=data.datetime.dt.year\n",
    "    test_months=data.datetime.dt.month\n",
    "    data=data.drop(['datetime'], axis = 1)\n",
    "    return np.array(data),np.array(test_years),np.array(test_months)\n",
    "    \n",
    "train2=copy(train)\n",
    "test2=copy(test)\n",
    "test=np.array(test)\n",
    "#print 'train2 is ',train2\n",
    "traind,labelsTrain,train_years,train_months,headers=extractFeaturesTrain(train2)\n",
    "testd,test_years,test_months=extractFeaturesTest(test2)\n",
    "\n",
    "submit=np.array((test.shape[0],2))\n",
    "\n",
    "#train.to_csv('Remodeled Train.csv')\n",
    "train=np.array(train)\n",
    "print 'train is \\n',traind.shape\n",
    "print 'labels train are \\n',labelsTrain.shape\n",
    "print 'test is \\n',testd.shape\n",
    "\n",
    "def findLocations(year,month):\n",
    "    locs=[]\n",
    "    for i in range(0,test.shape[0]):\n",
    "        if(test[i][0].year==year and test[i][0].month==month):\n",
    "            locs.append(i)\n",
    "        \n",
    "    return locs\n",
    "        \n",
    "def findValidDates(year,month):\n",
    "    locs=[]\n",
    "    for i in range(0,train.shape[0]):\n",
    "        if(train[i][0].year<=year and train[i][0].month<=month):\n",
    "            locs.append(i)\n",
    "    \n",
    "    return locs\n",
    "            \n",
    "'''for i in set(test_years):\n",
    "    for j in set(test_months):\n",
    "        print 'Year : ',i,' month ',j:\n",
    "            testLocs=findLocations(i,j)\n",
    "            testSubset=testd[testLocs]\n",
    "            \n",
    "            trainLocs=findValidDates(i,j)\n",
    "            trainSubset=traind[trainLocs]'''\n",
    "            \n",
    "def findLoss(gold,predicted):\n",
    "    loss=0\n",
    "    for i in range(gold.shape[0]):\n",
    "        loss+=(np.log(predicted[i]+1) -np.log(gold[i]+1))**2\n",
    "        \n",
    "    loss=loss/gold.shape[0]\n",
    "    #print 'loss is ',loss,' y_pred is ',predicted[i]\n",
    "    return np.sqrt(loss)\n",
    "\n",
    "def replaceNegaticeValuesWithZeroAndCountThem(ypred):\n",
    "    count=0\n",
    "    for i in range(ypred.shape[0]):\n",
    "        if(ypred[i]<0):\n",
    "            ypred[i]=0\n",
    "            count+=1\n",
    "    print 'Number of Negative values predicted are ',count\n",
    "    return ypred,count\n",
    "    \n",
    "\n",
    "rf=GradientBoostingRegressor()\n",
    "split1=0.8*traind.shape[0]\n",
    "trainSplit=traind[:split1,:]\n",
    "\n",
    "testSplit=traind[split1:,:]\n",
    "labelsSplitTrain=labelsTrain[:split1]\n",
    "labelsSplitTest=labelsTrain[split1:]\n",
    "rf.fit(trainSplit,labelsSplitTrain)\n",
    "ypred=rf.predict(testSplit)\n",
    "ypred,count=replaceNegaticeValuesWithZeroAndCountThem(ypred)\n",
    "print 'trainSplit is \\n',trainSplit.shape,' and testSplit is \\n',testSplit.shape\n",
    "print 'ypred is \\n',ypred\n",
    "print 'test split is \\n',labelsSplitTest\n",
    "print 'the loss is ',findLoss(labelsSplitTest,ypred)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "rf.fit(traind,labelsTrain)\n",
    "#print 'rf.estimators_ are ',rf.estimators_\n",
    "print 'testd shape is ',testd.shape\n",
    "ypred2=rf.predict(testd)\n",
    "with open('submit2.csv', 'wb') as csvfile:\n",
    "    resultWriter= csv.writer(csvfile)\n",
    "    l=['datetime','count']\n",
    "    resultWriter.writerow(l)\n",
    "    for i in range(testd.shape[0]):\n",
    "        #print 'test[',i,'][0] is ',test[i,0]\n",
    "        l=[test[i,0],ypred2[i]]\n",
    "        resultWriter.writerow(l)\n",
    "\n",
    "allEstimators=rf.estimators_\n",
    "allEstimators=allEstimators.reshape(1,-1)\n",
    "allEstimators=allEstimators.tolist()\n",
    "\n",
    "#print '2 rf.estimators_ are ',allEstimators[0]\n",
    "\n",
    "\n",
    "\n",
    "importances=rf.feature_importances_ \n",
    "std=np.std([tree.feature_importances_ for tree in allEstimators[0]],axis=0)\n",
    "indices=np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking\\n'\n",
    "\n",
    "for f in range(traind.shape[1]):\n",
    "    print(\"%d. feature %d %s (%f)\" % (f + 1, indices[f],headers[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "\n",
    "            \n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_title('Feature Importances By Gradient Boosted Trees')\n",
    "ax.bar(range(traind.shape[1]),importances[indices],color=\"b\",yerr=std[indices],align='center')\n",
    "plt.xticks(range(traind.shape[1]), indices)\n",
    "ax.set_xlim([-1, traind.shape[1]])\n",
    "ax.set_xticklabels(headers[indices])\n",
    "plt.savefig('Feature Importances By Gradient Boosted Trees')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_years are  set([2011, 2012])\n",
      "In testlocs year is = 2011  month is =  1\n",
      "For Random Forest year  2011  month  1\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  1\n",
      "Number of Negative values predicted are  14\n",
      "In testlocs year is = 2011  month is =  2\n",
      "For Random Forest year  2011  month  2\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  2\n",
      "Number of Negative values predicted are  4\n",
      "In testlocs year is = 2011  month is =  3\n",
      "For Random Forest year  2011  month  3\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  3\n",
      "Number of Negative values predicted are  13\n",
      "In testlocs year is = 2011  month is =  4\n",
      "For Random Forest year  2011  month  4\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  4\n",
      "Number of Negative values predicted are  8\n",
      "In testlocs year is = 2011  month is =  5\n",
      "For Random Forest year  2011  month  5\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  5\n",
      "Number of Negative values predicted are  11\n",
      "In testlocs year is = 2011  month is =  6\n",
      "For Random Forest year  2011  month  6\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  6\n",
      "Number of Negative values predicted are  0\n",
      "In testlocs year is = 2011  month is =  7\n",
      "For Random Forest year  2011  month  7\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  7\n",
      "Number of Negative values predicted are  0\n",
      "In testlocs year is = 2011  month is =  8\n",
      "For Random Forest year  2011  month  8\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  8\n",
      "Number of Negative values predicted are  0\n",
      "In testlocs year is = 2011  month is =  9\n",
      "For Random Forest year  2011  month  9\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  9\n",
      "Number of Negative values predicted are  4\n",
      "In testlocs year is = 2011  month is =  10\n",
      "For Random Forest year  2011  month  10\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  10\n",
      "Number of Negative values predicted are  4\n",
      "In testlocs year is = 2011  month is =  11\n",
      "For Random Forest year  2011  month  11\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  11\n",
      "Number of Negative values predicted are  6\n",
      "In testlocs year is = 2011  month is =  12\n",
      "For Random Forest year  2011  month  12\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2011  month  12\n",
      "Number of Negative values predicted are  25\n",
      "In testlocs year is = 2012  month is =  1\n",
      "For Random Forest year  2012  month  1\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  1\n",
      "Number of Negative values predicted are  38\n",
      "In testlocs year is = 2012  month is =  2\n",
      "For Random Forest year  2012  month  2\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  2\n",
      "Number of Negative values predicted are  11\n",
      "In testlocs year is = 2012  month is =  3\n",
      "For Random Forest year  2012  month  3\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  3\n",
      "Number of Negative values predicted are  16\n",
      "In testlocs year is = 2012  month is =  4\n",
      "For Random Forest year  2012  month  4\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  4\n",
      "Number of Negative values predicted are  9\n",
      "In testlocs year is = 2012  month is =  5\n",
      "For Random Forest year  2012  month  5\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  5\n",
      "Number of Negative values predicted are  3\n",
      "In testlocs year is = 2012  month is =  6\n",
      "For Random Forest year  2012  month  6\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  6\n",
      "Number of Negative values predicted are  8\n",
      "In testlocs year is = 2012  month is =  7\n",
      "For Random Forest year  2012  month  7\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  7\n",
      "Number of Negative values predicted are  13\n",
      "In testlocs year is = 2012  month is =  8\n",
      "For Random Forest year  2012  month  8\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  8\n",
      "Number of Negative values predicted are  0\n",
      "In testlocs year is = 2012  month is =  9\n",
      "For Random Forest year  2012  month  9\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  9\n",
      "Number of Negative values predicted are  8\n",
      "In testlocs year is = 2012  month is =  10\n",
      "For Random Forest year  2012  month  10\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  10\n",
      "Number of Negative values predicted are  3\n",
      "In testlocs year is = 2012  month is =  11\n",
      "For Random Forest year  2012  month  11\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  11\n",
      "Number of Negative values predicted are  3\n",
      "In testlocs year is = 2012  month is =  12\n",
      "For Random Forest year  2012  month  12\n",
      "Number of Negative values predicted are  0\n",
      "For Grandient Boosted Trees year  2012  month  12\n",
      "Number of Negative values predicted are  36\n"
     ]
    }
   ],
   "source": [
    "rf=RandomForestRegressor(150)\n",
    "gbt=GradientBoostingRegressor(n_estimators=300)\n",
    "\n",
    "\n",
    "print 'test_years are ',set(test_years)\n",
    "def getTestLocs(year,month):\n",
    "    \n",
    "    locs=[]\n",
    "    print 'In testlocs year is =',year,' month is = ',month\n",
    "    for i in range(0,test.shape[0]):\n",
    "        if test[i][0].year==year and test[i][0].month==month:\n",
    "            locs.append(i)\n",
    "    return locs\n",
    "\n",
    "with open('submitEnsembleOfRandomForestsAndGBT.csv','wb') as csvfile:\n",
    "    resultWriter=csv.writer(csvfile)\n",
    "    l=['datetime','count']\n",
    "    resultWriter.writerow(l)\n",
    "    for i in set(test_years):\n",
    "        for j in set(test_months):\n",
    "                testLocs=getTestLocs(i,j)\n",
    "                #print 'testLoics are ',testLocs\n",
    "                \n",
    "                testSubset1=testd[testLocs]\n",
    "                #print 'testSubset1 is ',testSubset1\n",
    "                testSubset2=test[testLocs]\n",
    "                #print 'testSubset2 is ',min(testSubset2[:,0])\n",
    "                #print 'testSubset2 is ',testSubset2\n",
    "                trainLocs=np.where(train[:,0]<=min(testSubset2[:,0]))\n",
    "                trainSubset=traind[trainLocs]\n",
    "                labelsSubset=labelsTrain[trainLocs]\n",
    "                rf.fit(trainSubset,labelsSubset)\n",
    "                gbt.fit(trainSubset,labelsSubset)\n",
    "                \n",
    "                #ypred3=rf2.predict(testSubset1)\n",
    "                #print 'Training Random Forest '\n",
    "                ypredRf=rf.predict(testSubset1)\n",
    "                #print 'Training Gradient Boosted Trees '\n",
    "                ypredGbt=gbt.predict(testSubset1)\n",
    "                \n",
    "                print 'For Random Forest year ',i,' month ',j\n",
    "                ypredRf,count1=replaceNegaticeValuesWithZeroAndCountThem(ypredRf)\n",
    "                print 'For Grandient Boosted Trees year ',i,' month ',j\n",
    "                ypredGbt,count2=replaceNegaticeValuesWithZeroAndCountThem(ypredGbt)\n",
    "                yensemble=[]\n",
    "                #print 'ypredRf is ',type(ypredRf),' \\n and ypredGbt is ',type(ypredGbt)\n",
    "                for m in range(ypredRf.shape[0]):\n",
    "                    if ypredRf[m]>0 and ypredGbt[m]>0:\n",
    "                        yensemble.append(ypredRf[m]/2+ypredGbt[m]/2)\n",
    "                    elif ypredRf[m]>0 and ypredGbt[m]==0:\n",
    "                        yensemble.append(ypredRf[m])\n",
    "                    elif ypredRf[m]==0 and ypredGbt[m]>0:\n",
    "                        yensemble.append(ypredGbt[m])\n",
    "                    else:\n",
    "                        yensemble.append(0)\n",
    "                        \n",
    "                \n",
    "                for k in range(0,testSubset2.shape[0]):\n",
    "                    l=[testSubset2[k,0],yensemble[k]]\n",
    "                    resultWriter.writerow(l)\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainSubset min is   2011-01-01 00:00:00  and max is  2011-11-19 23:00:00\n",
      "testSubset  min is   2011-12-01 00:00:00  and max is  2011-12-19 23:00:00\n",
      "Number of Negative values predicted are  0\n",
      "Number of Negative values predicted are  5\n",
      "Random Forest loss with year = 455  and month =  12  is  0.449498148039\n",
      "Gradient Boosted Trees loss with year = 455  and month =  12  is  0.499525255609\n",
      "Ensemble og Random Forest Gradient Boosted Trees loss with year = 455  and month =  12  is  0.425085880457\n",
      "trainSubset min is   2011-01-01 00:00:00  and max is  2012-11-19 23:00:00\n",
      "testSubset  min is   2012-12-01 00:00:00  and max is  2012-12-19 23:00:00\n",
      "Number of Negative values predicted are  0\n",
      "Number of Negative values predicted are  9\n",
      "Random Forest loss with year = 455  and month =  12  is  0.362786611535\n",
      "Gradient Boosted Trees loss with year = 455  and month =  12  is  0.591045997747\n",
      "Ensemble og Random Forest Gradient Boosted Trees loss with year = 455  and month =  12  is  0.386895734223\n"
     ]
    }
   ],
   "source": [
    "def getSplits(years,months):\n",
    "    locsTrain=[]\n",
    "    locsTest=[]\n",
    "    for i in range(0,train.shape[0]):\n",
    "            if (train[i,0].year==years[0] or train[i,0].year==years[1]) and (train[i,0].month in months):\n",
    "                locsTest.append(i)\n",
    "            else:\n",
    "                locsTrain.append(i) \n",
    "    \n",
    "    return locsTrain,locsTest\n",
    "\n",
    "def getCustomLocsTest(year,month,data):\n",
    "    locs=[]\n",
    "    for i in range(0,data.shape[0]):\n",
    "        if data[i][0].year==year and data[i][0].month==month:\n",
    "            locs.append(i)\n",
    "    return locs\n",
    "\n",
    "def crossValidate():\n",
    "        months=[12]\n",
    "        locsTrain,locsTest=getSplits([2011,2012],months)\n",
    "        \n",
    "        testSubset=traind[locsTest]\n",
    "        testSubset2=train[locsTest]\n",
    "        testLabels=labelsTrain[locsTest]\n",
    "        rf=RandomForestRegressor(100)\n",
    "        gbt=GradientBoostingRegressor(n_estimators=500)\n",
    "        \n",
    "        trainSubset=traind[locsTrain]\n",
    "        trainSubset2=train[locsTrain]\n",
    "        trainLabels=labelsTrain[locsTrain]\n",
    "        \n",
    "        for i in [2011,2012]:\n",
    "            for j in months:\n",
    "                testLocs=getCustomLocsTest(i,j,testSubset2)\n",
    "                testSubset3=testSubset2[testLocs]\n",
    "                testSubset4=testSubset[testLocs]\n",
    "                testLabels4=testLabels[testLocs]\n",
    "                \n",
    "                trainLocs2=np.where(trainSubset2[:,0]<=min(testSubset3[:,0]))\n",
    "                \n",
    "                trainSubset3=trainSubset[trainLocs2]\n",
    "                trainLabels3=trainLabels[trainLocs2]\n",
    "                x1=trainSubset2[trainLocs2]\n",
    "                x2=testSubset2[testLocs]\n",
    "                \n",
    "                print 'trainSubset min is  ', min(x1[:,0]),' and max is ',max(x1[:,0])\n",
    "                print 'testSubset  min is  ', min(x2[:,0]),' and max is ',max(x2[:,0])\n",
    "                \n",
    "                rf.fit(trainSubset3,trainLabels3)\n",
    "                gbt.fit(trainSubset3,trainLabels3)\n",
    "                \n",
    "                ypredRf=rf.predict(testSubset4)\n",
    "                ypredGbt=gbt.predict(testSubset4)\n",
    "                \n",
    "                ypredRf,count1=replaceNegaticeValuesWithZeroAndCountThem(ypredRf)\n",
    "                ypredGbt,count2=replaceNegaticeValuesWithZeroAndCountThem(ypredGbt)\n",
    "                yensemble=[]\n",
    "                #print 'ypredRf is ',type(ypredRf),' \\n and ypredGbt is ',type(ypredGbt)\n",
    "                for i in range(ypredRf.shape[0]):\n",
    "                    if ypredRf[i]>0 and ypredGbt[i]>0:\n",
    "                        yensemble.append(ypredRf[i]/2+ypredGbt[i]/2)\n",
    "                    elif ypredRf[i]>0 and ypredGbt[i]==0:\n",
    "                        yensemble.append(ypredRf[i])\n",
    "                    elif ypredRf[i]==0 and ypredGbt[i]>0:\n",
    "                        yensemble.append(ypredGbt[i])\n",
    "                    else:\n",
    "                        yensemble.append(0) #change here to append the mean sales of the week/month\n",
    "                    \n",
    "                \n",
    "                print 'Random Forest loss with year =',i,' and month = ',j,' is ',findLoss(testLabels4,ypredRf)\n",
    "                print 'Gradient Boosted Trees loss with year =',i,' and month = ',j,' is ',findLoss(testLabels4,ypredGbt)\n",
    "                print 'Ensemble og Random Forest Gradient Boosted Trees loss with year =',i,' and month = ',j,' is ',findLoss(testLabels4,yensemble)\n",
    "crossValidate() \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
